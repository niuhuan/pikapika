#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import os
import sys
import argparse
from pathlib import Path
from typing import Dict, List, Set, Any
from datetime import datetime

def flatten_json(data: Dict[str, Any], parent_key: str = '', separator: str = '.') -> Dict[str, Any]:
    """
    å°†åµŒå¥—çš„JSONå¯¹è±¡æ‰å¹³åŒ–ä¸ºç‚¹åˆ†éš”çš„é”®å€¼å¯¹
    
    Args:
        data: è¦æ‰å¹³åŒ–çš„JSONæ•°æ®
        parent_key: çˆ¶çº§é”®å
        separator: é”®ååˆ†éš”ç¬¦
    
    Returns:
        æ‰å¹³åŒ–åçš„å­—å…¸
    """
    items = []
    for key, value in data.items():
        new_key = f"{parent_key}{separator}{key}" if parent_key else key
        if isinstance(value, dict):
            items.extend(flatten_json(value, new_key, separator).items())
        else:
            items.append((new_key, value))
    return dict(items)

def unflatten_json(data: Dict[str, Any], separator: str = '.') -> Dict[str, Any]:
    """
    å°†æ‰å¹³åŒ–çš„JSONå¯¹è±¡è¿˜åŸä¸ºåµŒå¥—ç»“æ„
    
    Args:
        data: æ‰å¹³åŒ–çš„JSONæ•°æ®
        separator: é”®ååˆ†éš”ç¬¦
    
    Returns:
        åµŒå¥—çš„JSONå¯¹è±¡
    """
    result = {}
    for key, value in data.items():
        parts = key.split(separator)
        current = result
        for part in parts[:-1]:
            if part not in current:
                current[part] = {}
            current = current[part]
        current[parts[-1]] = value
    return result

def load_json_file(file_path: str) -> Dict[str, Any]:
    """
    åŠ è½½JSONæ–‡ä»¶
    
    Args:
        file_path: JSONæ–‡ä»¶è·¯å¾„
    
    Returns:
        JSONæ•°æ®å­—å…¸
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return {}
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æé”™è¯¯ {file_path}: {e}")
        return {}
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶é”™è¯¯ {file_path}: {e}")
        return {}

def save_json_file(file_path: str, data: Dict[str, Any]) -> bool:
    """
    ä¿å­˜JSONæ–‡ä»¶
    
    Args:
        file_path: JSONæ–‡ä»¶è·¯å¾„
        data: è¦ä¿å­˜çš„æ•°æ®
    
    Returns:
        æ˜¯å¦ä¿å­˜æˆåŠŸ
    """
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶é”™è¯¯ {file_path}: {e}")
        return False

def get_all_json_files(translations_dir: str) -> List[str]:
    """
    è·å–ç¿»è¯‘ç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶
    
    Args:
        translations_dir: ç¿»è¯‘æ–‡ä»¶ç›®å½•
    
    Returns:
        JSONæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    json_files = []
    if os.path.exists(translations_dir):
        for file in os.listdir(translations_dir):
            if file.endswith('.json'):
                json_files.append(os.path.join(translations_dir, file))
    return sorted(json_files)

def find_reference_value(key: str, all_data: Dict[str, Dict[str, Any]]) -> str:
    """
    ä¸ºç¼ºå¤±çš„é”®æ‰¾åˆ°å‚è€ƒå€¼
    
    Args:
        key: ç¼ºå¤±çš„é”®
        all_data: æ‰€æœ‰ç¿»è¯‘æ•°æ®
    
    Returns:
        å‚è€ƒå€¼æˆ–å ä½ç¬¦
    """
    # é¦–å…ˆå°è¯•ä»å…¶ä»–æ–‡ä»¶ä¸­æ‰¾åˆ°è¿™ä¸ªé”®çš„å€¼
    for filename, data in all_data.items():
        flattened = flatten_json(data)
        if key in flattened:
            return flattened[key]
    
    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œç”Ÿæˆä¸€ä¸ªå ä½ç¬¦
    key_parts = key.split('.')
    last_part = key_parts[-1]
    
    # æ ¹æ®é”®åç”Ÿæˆåˆç†çš„å ä½ç¬¦
    placeholders = {
        'title': 'Title',
        'name': 'Name',
        'description': 'Description',
        'hint': 'Hint',
        'label': 'Label',
        'placeholder': 'Placeholder',
        'button': 'Button',
        'confirm': 'Confirm',
        'cancel': 'Cancel',
        'yes': 'Yes',
        'no': 'No',
        'loading': 'Loading...',
        'error': 'Error',
        'success': 'Success',
        'failed': 'Failed',
        'warning': 'Warning',
    }
    
    for placeholder_key, placeholder_value in placeholders.items():
        if placeholder_key in last_part.lower():
            return placeholder_value
    
    # é»˜è®¤å ä½ç¬¦
    return f"TODO: {last_part.replace('_', ' ').title()}"

def generate_missing_keys_report(translations_dir: str, output_file: str = None):
    """
    ç”Ÿæˆç¼ºå¤±é”®çš„æŠ¥å‘Š
    
    Args:
        translations_dir: ç¿»è¯‘æ–‡ä»¶ç›®å½•
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    json_files = get_all_json_files(translations_dir)
    
    if not json_files:
        print(f"âŒ åœ¨ç›®å½• {translations_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
        return
    
    # åŠ è½½æ‰€æœ‰JSONæ–‡ä»¶
    all_data = {}
    all_keys = {}
    
    for file_path in json_files:
        filename = os.path.basename(file_path)
        data = load_json_file(file_path)
        if data:
            all_data[filename] = data
            all_keys[filename] = set(flatten_json(data).keys())
    
    if not all_data:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•JSONæ–‡ä»¶")
        return
    
    # æ‰¾å‡ºæ‰€æœ‰é”®çš„å¹¶é›†
    all_possible_keys = set()
    for keys in all_keys.values():
        all_possible_keys.update(keys)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = []
    report.append(f"# ç¿»è¯‘æ–‡ä»¶ç¼ºå¤±é”®æŠ¥å‘Š")
    report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"ç¿»è¯‘æ–‡ä»¶ç›®å½•: {translations_dir}")
    report.append(f"æ€»é”®æ•°: {len(all_possible_keys)}")
    report.append("")
    
    # ç»Ÿè®¡ä¿¡æ¯
    report.append("## ç»Ÿè®¡ä¿¡æ¯")
    report.append("| æ–‡ä»¶å | é”®æ•°é‡ | ç¼ºå¤±é”®æ•°é‡ |")
    report.append("|--------|--------|------------|")
    
    for filename, keys in all_keys.items():
        missing_count = len(all_possible_keys - keys)
        report.append(f"| {filename} | {len(keys)} | {missing_count} |")
    
    report.append("")
    
    # è¯¦ç»†ç¼ºå¤±ä¿¡æ¯
    report.append("## ç¼ºå¤±é”®è¯¦æƒ…")
    
    for filename, keys in all_keys.items():
        missing_keys = all_possible_keys - keys
        if missing_keys:
            report.append(f"### {filename}")
            report.append(f"ç¼ºå¤± {len(missing_keys)} ä¸ªé”®:")
            for key in sorted(missing_keys):
                report.append(f"- `{key}`")
            report.append("")
    
    # è¾“å‡ºæŠ¥å‘Š
    report_content = "\n".join(report)
    
    if output_file:
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report_content)
            print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
    else:
        print(report_content)

def fix_missing_keys(translations_dir: str, dry_run: bool = True):
    """
    ä¿®å¤ç¼ºå¤±çš„é”®
    
    Args:
        translations_dir: ç¿»è¯‘æ–‡ä»¶ç›®å½•
        dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œæ¨¡å¼
    """
    json_files = get_all_json_files(translations_dir)
    
    if not json_files:
        print(f"âŒ åœ¨ç›®å½• {translations_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
        return
    
    # åŠ è½½æ‰€æœ‰JSONæ–‡ä»¶
    all_data = {}
    all_keys = {}
    
    for file_path in json_files:
        filename = os.path.basename(file_path)
        data = load_json_file(file_path)
        if data:
            all_data[filename] = data
            all_keys[filename] = set(flatten_json(data).keys())
    
    if not all_data:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•JSONæ–‡ä»¶")
        return
    
    # æ‰¾å‡ºæ‰€æœ‰é”®çš„å¹¶é›†
    all_possible_keys = set()
    for keys in all_keys.values():
        all_possible_keys.update(keys)
    
    # ä¿®å¤æ¯ä¸ªæ–‡ä»¶çš„ç¼ºå¤±é”®
    for file_path in json_files:
        filename = os.path.basename(file_path)
        if filename not in all_data:
            continue
        
        missing_keys = all_possible_keys - all_keys[filename]
        if not missing_keys:
            print(f"âœ… {filename} æ— éœ€ä¿®å¤")
            continue
        
        print(f"ğŸ”§ {'[è¯•è¿è¡Œ] ' if dry_run else ''}ä¿®å¤ {filename} çš„ {len(missing_keys)} ä¸ªç¼ºå¤±é”®:")
        
        # è·å–å½“å‰æ–‡ä»¶çš„æ‰å¹³åŒ–æ•°æ®
        flattened_data = flatten_json(all_data[filename])
        
        # æ·»åŠ ç¼ºå¤±çš„é”®
        for key in sorted(missing_keys):
            reference_value = find_reference_value(key, all_data)
            flattened_data[key] = reference_value
            print(f"  + {key} = \"{reference_value}\"")
        
        # å¦‚æœä¸æ˜¯è¯•è¿è¡Œï¼Œä¿å­˜æ–‡ä»¶
        if not dry_run:
            # å°†æ‰å¹³åŒ–æ•°æ®è¿˜åŸä¸ºåµŒå¥—ç»“æ„
            nested_data = unflatten_json(flattened_data)
            
            # ä¿å­˜æ–‡ä»¶
            if save_json_file(file_path, nested_data):
                print(f"  âœ… å·²ä¿å­˜ {filename}")
            else:
                print(f"  âŒ ä¿å­˜ {filename} å¤±è´¥")
        
        print()

def compare_translation_files(translations_dir: str):
    """
    æ¯”è¾ƒç¿»è¯‘æ–‡ä»¶ï¼Œæ‰¾å‡ºç¼ºå¤±çš„é”®
    
    Args:
        translations_dir: ç¿»è¯‘æ–‡ä»¶ç›®å½•
    """
    json_files = get_all_json_files(translations_dir)
    
    if not json_files:
        print(f"âŒ åœ¨ç›®å½• {translations_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
        return
    
    print(f"ğŸ” æ‰¾åˆ° {len(json_files)} ä¸ªç¿»è¯‘æ–‡ä»¶:")
    for file in json_files:
        print(f"  - {os.path.basename(file)}")
    print()
    
    # åŠ è½½æ‰€æœ‰JSONæ–‡ä»¶
    all_data = {}
    all_keys = {}
    
    for file_path in json_files:
        filename = os.path.basename(file_path)
        data = load_json_file(file_path)
        if data:
            all_data[filename] = data
            all_keys[filename] = set(flatten_json(data).keys())
        else:
            print(f"âš ï¸  è·³è¿‡ç©ºæ–‡ä»¶: {filename}")
    
    if not all_data:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•JSONæ–‡ä»¶")
        return
    
    # æ‰¾å‡ºæ‰€æœ‰é”®çš„å¹¶é›†
    all_possible_keys = set()
    for keys in all_keys.values():
        all_possible_keys.update(keys)
    
    print(f"ğŸ“Š æ€»å…±å‘ç° {len(all_possible_keys)} ä¸ªå”¯ä¸€é”®")
    print()
    
    # æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶ç¼ºå¤±çš„é”®
    has_missing_keys = False
    
    for filename, keys in all_keys.items():
        missing_keys = all_possible_keys - keys
        if missing_keys:
            has_missing_keys = True
            print(f"âŒ {filename} ç¼ºå¤± {len(missing_keys)} ä¸ªé”®:")
            for key in sorted(missing_keys):
                print(f"  - {key}")
            print()
        else:
            print(f"âœ… {filename} åŒ…å«æ‰€æœ‰é”®")
    
    if not has_missing_keys:
        print("ğŸ‰ æ‰€æœ‰ç¿»è¯‘æ–‡ä»¶éƒ½åŒ…å«ç›¸åŒçš„é”®ï¼")
        return
    
    # æ˜¾ç¤ºé”®ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“ˆ é”®ç»Ÿè®¡ä¿¡æ¯:")
    print(f"{'æ–‡ä»¶å':<20} {'é”®æ•°é‡':<10} {'ç¼ºå¤±é”®æ•°é‡':<12}")
    print("-" * 45)
    
    for filename, keys in all_keys.items():
        missing_count = len(all_possible_keys - keys)
        print(f"{filename:<20} {len(keys):<10} {missing_count:<12}")
    
    # æ‰¾å‡ºåªåœ¨æŸäº›æ–‡ä»¶ä¸­å­˜åœ¨çš„é”®
    print("\nğŸ” é”®åˆ†å¸ƒåˆ†æ:")
    key_distribution = {}
    for key in all_possible_keys:
        files_with_key = [filename for filename, keys in all_keys.items() if key in keys]
        key_distribution[key] = files_with_key
    
    # æ‰¾å‡ºä¸åœ¨æ‰€æœ‰æ–‡ä»¶ä¸­çš„é”®
    incomplete_keys = {key: files for key, files in key_distribution.items() if len(files) < len(all_keys)}
    
    if incomplete_keys:
        print(f"å‘ç° {len(incomplete_keys)} ä¸ªé”®ä¸åœ¨æ‰€æœ‰æ–‡ä»¶ä¸­:")
        for key, files in sorted(incomplete_keys.items()):
            missing_files = [f for f in all_keys.keys() if f not in files]
            print(f"  {key}")
            print(f"    å­˜åœ¨äº: {', '.join(files)}")
            print(f"    ç¼ºå¤±äº: {', '.join(missing_files)}")
            print()
    else:
        print("æ‰€æœ‰é”®éƒ½åœ¨æ‰€æœ‰æ–‡ä»¶ä¸­å­˜åœ¨ï¼")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ¯”è¾ƒç¿»è¯‘æ–‡ä»¶ä¸­çš„é”®ï¼Œæ‰¾å‡ºç¼ºå¤±çš„é”®')
    parser.add_argument('translations_dir', nargs='?', 
                       help='ç¿»è¯‘æ–‡ä»¶ç›®å½•è·¯å¾„ (é»˜è®¤: ../lib/assets/translations)')
    parser.add_argument('--report', '-r', metavar='FILE',
                       help='ç”ŸæˆæŠ¥å‘Šå¹¶ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶')
    parser.add_argument('--fix', '-f', action='store_true',
                       help='ä¿®å¤ç¼ºå¤±çš„é”®')
    parser.add_argument('--dry-run', '-d', action='store_true',
                       help='è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶')
    
    args = parser.parse_args()
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # ç¿»è¯‘æ–‡ä»¶ç›®å½•è·¯å¾„
    if args.translations_dir:
        translations_dir = args.translations_dir
    else:
        translations_dir = os.path.join(script_dir, '..', 'lib', 'assets', 'translations')
        translations_dir = os.path.normpath(translations_dir)
    
    print(f"ğŸš€ å¼€å§‹æ¯”è¾ƒç¿»è¯‘æ–‡ä»¶...")
    print(f"ğŸ“ ç¿»è¯‘æ–‡ä»¶ç›®å½•: {translations_dir}")
    print()
    
    if not os.path.exists(translations_dir):
        print(f"âŒ ç¿»è¯‘æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨: {translations_dir}")
        sys.exit(1)
    
    if args.report:
        generate_missing_keys_report(translations_dir, args.report)
    elif args.fix:
        fix_missing_keys(translations_dir, dry_run=args.dry_run)
    else:
        compare_translation_files(translations_dir)

if __name__ == "__main__":
    main()
